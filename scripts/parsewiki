import requests
import re
import json
import pandas as pd

def get_wiki_json(title, print_url=False):
    " Function to get the wikitext, based on character name"
    # check formatting of the tiltle
    title = "_".join(title.split())
    url = f"https://gameofthrones.fandom.com/api.php?action=query&format=json&titles={title}&prop=revisions&rvprop=content&"
    if print_url==True:
        print('url:', url)
    reg = requests.get(url)
    return reg.text

def get_text_fromwiki(txt):
    # try except cactching all errors from trying to get the text
    # if it fails its because the wiki site does not exsist ect.
    try:
        js = json.loads(txt)
        key = js.get("query").get("pages").keys()
        key = list(key)[-1]
        out = js.get("query").get("pages").get(key).get("revisions")
        out = out[0].get("*")
        return out
    except :
        return ''

def extract_attr(attr):
    # Extract Affiliation or House
    # Match everything from the attribute
    all_matches = re.search(attr + r'\s*=.+', wikitext)
    # split it from the newline
    # Then extract all links
    matches = list()
    if all_matches is not None:
        match = all_matches.group(0).split('\n')
        matches = re.findall(r'\[\[([^\|^\]]+)\|?[^\]]*\]\]', all_matches.group(0))
    # remove ward from list
    matches = [x for x in matches if x not in ['ward']]
    return matches

def GatherLinks(text): 
    links = re.findall("\[\[[^\]]+\]\]", text)
    finalList = list()
    for link in links:
        finalList.append(link.strip("[[").strip("]]").split("|")[0])
    return(finalList)

def get_all_characters(EpisodeList, print_url=False):
    with open(EpisodeList, 'r') as f:
        characters = set()
        for line in f:
            episode = line.strip()
            wikijson = get_wiki_json(episode, print_url=print_url)
            wikitext = get_text_fromwiki(wikijson)
            links = GatherLinks(wikitext)
            characters.update(links)
    characters = set(characters)
    return characters


if __name__ == "__main__":
    # Get data for Petyr Baelish as an example
    wikijson = get_wiki_json('Petyr Baelish', print_url=True) # Also prints url it tries
    wikitext = get_text_fromwiki(wikijson)
    print(extract_attr('Affiliation'))
    print(extract_attr('House'))

    # Get all charcters
    EpisodeList = '../data/EpisodeList.txt'
    character_set = get_all_characters(EpisodeList, print_url=True)

    # Get data for each character found
    char_info = dict()
    for i, character in enumerate(character_set):
        print(i, 'of', len(character_set), character)
        if re.match(r'[\w\s_]*', character) is not None:
            wikijson = get_wiki_json(character, print_url=False) # Also prints url it tries
            wikitext = get_text_fromwiki(wikijson)
            affil = extract_attr('Affiliation')
            house = extract_attr('House')
            char_info[character] = [house, affil]
        else:
            print('not adding', character)
        #if i == 10:
        #    break
    df = pd.DataFrame.from_dict(char_info, orient='index')
    df.to_csv('../data/characher_metadata.csv')
